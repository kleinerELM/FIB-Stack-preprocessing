{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# image alignment tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import napari\n",
    "\n",
    "from align import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder='E:/2020_11_18 C3S 28d+EDX (2 Teile)/2020_11_19 C3S 28d+EDX/Images/SEM Image/'\n",
    "folder='E:/2020_11_18 C3S 28d+EDX (2 Teile)/2020_11_19 C3S 28d+EDX/Images/EDS/'\n",
    "folder='E:/2020_11_18 C3S 28d+EDX (2 Teile)/2020_11_19 C3S 28d+EDX/EDS Export/'\n",
    "#folder='E:/SEM Image/'\n",
    "folder='F:/2020_11_19 C3S 28d+EDX/EDS Export/'\n",
    "sem_folder='F:/2020_11_19 C3S 28d+EDX/Images/SEM Image/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "identified 14 elements\n"
     ]
    }
   ],
   "source": [
    "folder, eds_elements = check_folder_structure(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loading 80 images...\n",
      "((96000, 1000),)\n",
      "((96000, 1000),)\n",
      "  Image is an EDS image of the FIB process\n",
      "  26.943 x 26.943 nm/px\n",
      "\n",
      "Found existing translation csv, loading...\n",
      "Create 3D image stack with corrected image translation\n",
      "  - allocating 3D image space..\n",
      "  - translating and denoising images..\n",
      "saving images..\n",
      "saved \"F:/2020_11_19 C3S 28d+EDX/EDS Export/Images\\aligned\\aligned_stack_(80).tif\"\n",
      "sucessfull\n"
     ]
    }
   ],
   "source": [
    "sem_translation, error_list, filled_canvas, loaded_images, scaling = process_translation_of_folder(folder=folder, multicore=True, do_nlm=False, mask_size=0.99, eq_hist=True, crop_thresh=0 )\n",
    "\n",
    "im_cnt = len(loaded_images)\n",
    "z_scale=192\n",
    "\n",
    "scale=(z_scale, scaling['y'], scaling['x'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add a shape and mark the top line of the cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### correction of the y-translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found existing translation csv, loading...\n"
     ]
    }
   ],
   "source": [
    "translation   = sem_translation.copy()\n",
    "\n",
    "translation_csv = folder + os.sep + 'translations_fixed_y.csv'\n",
    "fixed_translation = load_translation_csv( translation_csv, im_cnt )\n",
    "if len(fixed_translation) != im_cnt-1:\n",
    "    with napari.gui_qt():\n",
    "        viewer = napari.view_image(filled_canvas, name='select y correction line', scale=scale )\n",
    "\n",
    "    correction_dict = {}\n",
    "    for point in viewer.layers[1].data[0]:\n",
    "        correction_dict[math.floor(point[0])] = point[1]\n",
    "\n",
    "    y_correction_list = get_axis_correction_list( correction_dict, im_cnt )\n",
    "\n",
    "    for i, y in enumerate(y_correction_list):\n",
    "        # print(i, y, translation[i-1][1], translation[i-1][1] - y)\n",
    "        if i>0: translation[i-1][1] -= y\n",
    "    save_translation_csv( translation, translation_csv)\n",
    "else:\n",
    "    translation = fixed_translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### correction of the x-translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found existing translation csv, loading...\nCreate 3D image stack with corrected image translation\n  - allocating 3D image space..\n  - translating and denoising images..\n"
     ]
    }
   ],
   "source": [
    "translation_csv = folder + os.sep + 'translations_fixed_xy.csv'\n",
    "fixed_translation = load_translation_csv( translation_csv, im_cnt )\n",
    "if len(fixed_translation) != im_cnt-1:\n",
    "    corrected_images = create_3D_stack(translation, loaded_images, False)\n",
    "    with napari.gui_qt():\n",
    "        viewer = napari.view_image(corrected_images, name='select x correction line', scale=scale )\n",
    "        viewer.scale_bar.visible = True\n",
    "\n",
    "    correction_dict = {}\n",
    "    for point in viewer.layers[1].data[0]:\n",
    "        correction_dict[math.floor(point[0])] = point[0]\n",
    "\n",
    "    x_correction_list = get_axis_correction_list( correction_dict, z_slice_count )\n",
    "\n",
    "    for i, x in enumerate(x_correction_list):\n",
    "        # print(i, y, translation[i-1][2], translation[i-1][2] - x)\n",
    "        if i>0: translation[i-1][2] += x\n",
    "    save_translation_csv( translation, translation_csv)\n",
    "\n",
    "    # show final stack arrangement\n",
    "    corrected_sem_images = create_3D_stack(translation, loaded_images, False)\n",
    "    with napari.gui_qt():\n",
    "        viewer = napari.view_image(corrected_sem_images, name='test2', scale=scale)\n",
    "        viewer.scale_bar.visible = True\n",
    "else:\n",
    "    translation = fixed_translation\n",
    "    corrected_sem_images = create_3D_stack(translation, loaded_images, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\nprint(round(len(loaded_images)/3), round(len(loaded_eds_images)/3))\\n\\n#1 get representative SEM image\\nimg_sem = loaded_images[19]\\n\\n#2 get same plane for a specific element EDS images\\nselected_element = \"Pt\"\\nfolder = eds_elements[selected_element]\\n_, loaded_eds_images = load_image_set(folder)\\nimg_pt  = loaded_eds_images[1]\\n\\nclahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(1,1))\\n#3 get thresholded images of both images\\nimg_sem = cv2.GaussianBlur(clahe.apply(cv2.medianBlur(img_sem, 5)), (5, 5), cv2.BORDER_DEFAULT)\\nimg_pt  = cv2.GaussianBlur(clahe.apply(cv2.medianBlur(img_pt,  9)),  (15, 15), cv2.BORDER_DEFAULT)\\n\\n#_, img_sem_bin = cv2.threshold( clahe.apply(cv2.medianBlur(img_sem, 5)) , 125, 255, cv2.THRESH_BINARY)\\n#_, img_pt_bin  = cv2.threshold( clahe.apply(cv2.medianBlur(img_pt,  5)) ,  60, 255, cv2.THRESH_BINARY)\\n\\ncol = 2\\nrow = 1\\nfig=plt.figure(figsize=(col*5, row*5))\\nplt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, \\n            hspace = 0, wspace = 0)\\n            \\nplt.margins(0,0)\\nplt.axis(\\'off\\')\\nfig.add_subplot(row, col, 1)\\n\\nplt.axis(\\'off\\')\\nplt.imshow(img_sem, cmap=\\'gray\\')\\n\\nfig.add_subplot(row, col, 2)\\nplt.axis(\\'off\\')\\nplt.imshow(img_pt, cmap=\\'gray\\')\\n\\nmask      = None\\nmask_full = None\\n\\n#4 get the translation of the repective images\\nget_image_translation(\\'asdf\\', img_sem, img_pt, mask, mask_full)\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# sadly the automatic translation did not work\n",
    "\"\"\"\n",
    "print(round(len(loaded_images)/3), round(len(loaded_eds_images)/3))\n",
    "\n",
    "#1 get representative SEM image\n",
    "img_sem = loaded_images[19]\n",
    "\n",
    "#2 get same plane for a specific element EDS images\n",
    "selected_element = \"Pt\"\n",
    "folder = eds_elements[selected_element]\n",
    "_, loaded_eds_images = load_image_set(folder)\n",
    "img_pt  = loaded_eds_images[1]\n",
    "\n",
    "clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(1,1))\n",
    "#3 get thresholded images of both images\n",
    "img_sem = cv2.GaussianBlur(clahe.apply(cv2.medianBlur(img_sem, 5)), (5, 5), cv2.BORDER_DEFAULT)\n",
    "img_pt  = cv2.GaussianBlur(clahe.apply(cv2.medianBlur(img_pt,  9)),  (15, 15), cv2.BORDER_DEFAULT)\n",
    "\n",
    "#_, img_sem_bin = cv2.threshold( clahe.apply(cv2.medianBlur(img_sem, 5)) , 125, 255, cv2.THRESH_BINARY)\n",
    "#_, img_pt_bin  = cv2.threshold( clahe.apply(cv2.medianBlur(img_pt,  5)) ,  60, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "col = 2\n",
    "row = 1\n",
    "fig=plt.figure(figsize=(col*5, row*5))\n",
    "plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, \n",
    "            hspace = 0, wspace = 0)\n",
    "            \n",
    "plt.margins(0,0)\n",
    "plt.axis('off')\n",
    "fig.add_subplot(row, col, 1)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.imshow(img_sem, cmap='gray')\n",
    "\n",
    "fig.add_subplot(row, col, 2)\n",
    "plt.axis('off')\n",
    "plt.imshow(img_pt, cmap='gray')\n",
    "\n",
    "mask      = None\n",
    "mask_full = None\n",
    "\n",
    "#4 get the translation of the repective images\n",
    "get_image_translation('asdf', img_sem, img_pt, mask, mask_full)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"\\ndef get_full_img_translation( translation, search_pos, verbose = False ):\\n    x_t = 0\\n    y_t = 0\\n    min_x = 0\\n    min_y = 0\\n    if verbose: print('~'*20)\\n    for pos, step in enumerate(translation):\\n        if verbose: print(pos, (step[2], step[1]), (x_t+step[2], y_t+step[1]))\\n        if pos <= search_pos:\\n            x_t += step[2]\\n            y_t += step[1]\\n        if pos==search_pos:\\n            if verbose: print('this translation', step)\\n        if min_x > step[2]: min_x = step[2]\\n        if min_y > step[1]: min_y = step[1]\\n\\n    return (min_x, x_t), (min_y, y_t)\\nprint( get_full_img_translation( translation, 17, True ) )\\n\""
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "\"\"\"\n",
    "def get_full_img_translation( translation, search_pos, verbose = False ):\n",
    "    x_t = 0\n",
    "    y_t = 0\n",
    "    min_x = 0\n",
    "    min_y = 0\n",
    "    if verbose: print('~'*20)\n",
    "    for pos, step in enumerate(translation):\n",
    "        if verbose: print(pos, (step[2], step[1]), (x_t+step[2], y_t+step[1]))\n",
    "        if pos <= search_pos:\n",
    "            x_t += step[2]\n",
    "            y_t += step[1]\n",
    "        if pos==search_pos:\n",
    "            if verbose: print('this translation', step)\n",
    "        if min_x > step[2]: min_x = step[2]\n",
    "        if min_y > step[1]: min_y = step[1]\n",
    "\n",
    "    return (min_x, x_t), (min_y, y_t)\n",
    "print( get_full_img_translation( translation, 17, True ) )\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load EDS images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ignoring Ag\n",
      "ignoring Al\n",
      "ignoring Ar\n",
      "--------------------\n",
      "selected element is C\n",
      "loading 80 images...\n",
      " Found multiple shapes!\n",
      "  found 17 images with this shape: (654, 565)\n",
      "  found 63 images with this shape: (624, 515)\n",
      "  - eds x translation: 404.8 - -132.3115293083519 + -65.33373174191244 \n",
      "  - eds y translation: 50.8 - -24.07718880962004 + -22.62759310139859 \n",
      "  - final translation 471.77779756643946 and 52.24959570822145\n",
      "1.4495957082214517\n",
      "['Elektronenbild 21.tif', 1.4495957082214526, 2.010848378460873]\n",
      " denoising images and enhance contrast\n",
      "Create 3D image stack with corrected image translation\n",
      "found first_x_offset: 471.77779756643946\n",
      "found first_y_offset: 52.24959570822145\n",
      "  - allocating 3D image space..\n",
      "  - translating and denoising images..\n",
      "ignoring Ca\n",
      "ignoring Cl\n",
      "ignoring Cu\n",
      "--------------------\n",
      "selected element is Ga\n",
      "loading 80 images...\n",
      " Found multiple shapes!\n",
      "  found 17 images with this shape: (654, 565)\n",
      "  found 63 images with this shape: (624, 515)\n",
      "  - eds x translation: 404.8 - -132.3115293083519 + -65.33373174191244 \n",
      "  - eds y translation: 50.8 - -24.07718880962004 + -22.62759310139859 \n",
      "  - final translation 471.77779756643946 and 52.24959570822145\n",
      "1.4495957082214517\n",
      "['Elektronenbild 21.tif', 1.4495957082214526, 2.010848378460873]\n",
      " denoising images and enhance contrast\n",
      "Create 3D image stack with corrected image translation\n",
      "found first_x_offset: 471.77779756643946\n",
      "found first_y_offset: 52.24959570822145\n",
      "  - allocating 3D image space..\n",
      "  - translating and denoising images..\n",
      "ignoring Lu\n",
      "ignoring Mg\n",
      "--------------------\n",
      "selected element is O\n",
      "loading 80 images...\n",
      " Found multiple shapes!\n",
      "  found 17 images with this shape: (654, 565)\n",
      "  found 63 images with this shape: (624, 515)\n",
      "  - eds x translation: 404.8 - -132.3115293083519 + -65.33373174191244 \n",
      "  - eds y translation: 50.8 - -24.07718880962004 + -22.62759310139859 \n",
      "  - final translation 471.77779756643946 and 52.24959570822145\n",
      "1.4495957082214517\n",
      "['Elektronenbild 21.tif', 1.4495957082214526, 2.010848378460873]\n",
      " denoising images and enhance contrast\n",
      "Create 3D image stack with corrected image translation\n",
      "found first_x_offset: 471.77779756643946\n",
      "found first_y_offset: 52.24959570822145\n",
      "  - allocating 3D image space..\n",
      "  - translating and denoising images..\n",
      "--------------------\n",
      "selected element is Pt\n",
      "loading 80 images...\n",
      " Found multiple shapes!\n",
      "  found 17 images with this shape: (654, 565)\n",
      "  found 63 images with this shape: (624, 515)\n",
      "  - eds x translation: 404.8 - -132.3115293083519 + -65.33373174191244 \n",
      "  - eds y translation: 50.8 - -24.07718880962004 + -22.62759310139859 \n",
      "  - final translation 471.77779756643946 and 52.24959570822145\n",
      "1.4495957082214517\n",
      "['Elektronenbild 21.tif', 1.4495957082214526, 2.010848378460873]\n",
      " denoising images and enhance contrast\n",
      "Create 3D image stack with corrected image translation\n",
      "found first_x_offset: 471.77779756643946\n",
      "found first_y_offset: 52.24959570822145\n",
      "  - allocating 3D image space..\n",
      "  - translating and denoising images..\n",
      "--------------------\n",
      "selected element is Si\n",
      "loading 80 images...\n",
      " Found multiple shapes!\n",
      "  found 17 images with this shape: (654, 565)\n",
      "  found 63 images with this shape: (624, 515)\n",
      "  - eds x translation: 404.8 - -132.3115293083519 + -65.33373174191244 \n",
      "  - eds y translation: 50.8 - -24.07718880962004 + -22.62759310139859 \n",
      "  - final translation 471.77779756643946 and 52.24959570822145\n",
      "1.4495957082214517\n",
      "['Elektronenbild 21.tif', 1.4495957082214526, 2.010848378460873]\n",
      " denoising images and enhance contrast\n",
      "Create 3D image stack with corrected image translation\n",
      "found first_x_offset: 471.77779756643946\n",
      "found first_y_offset: 52.24959570822145\n",
      "  - allocating 3D image space..\n",
      "  - translating and denoising images..\n",
      "ignoring Tb\n",
      "translate and display image stack using the following voxel dimensions: x=26.94, y=28.21, z=192.00 nm\n",
      "0 C\n",
      "1 Ga\n",
      "2 O\n",
      "3 Pt\n",
      "4 Si\n"
     ]
    }
   ],
   "source": [
    "eds_x_offset = 404.8#+22\n",
    "eds_y_offset = 50.8\n",
    "#expected_img_count = 63\n",
    "relevant_elements = ['Ga', 'Si', 'O', 'Pt', 'C']\n",
    "colormaps = [\"red\", \"green\", \"blue\", \"yellow\", \"magenta\"]\n",
    "\n",
    "if len(eds_elements) > 0:\n",
    "\n",
    "    scale=(z_scale, scaling['y'], scaling['x'])\n",
    "    image_stacks = {}\n",
    "    for element in eds_elements.keys():\n",
    "        if element in relevant_elements:\n",
    "            stack = process_element(eds_elements, element, translation, eds_x_offset, eds_y_offset)\n",
    "            if len(stack) != len(loaded_images):\n",
    "                print('Dataset for {} is incomplete ({} != {})'.format(element, len(stack), len(loaded_images)))\n",
    "            else:\n",
    "                image_stacks[element] = stack\n",
    "        else:\n",
    "            print('ignoring {}'.format(element))\n",
    "\n",
    "    # show image stacks\n",
    "    print('translate and display image stack using the following voxel dimensions: x={:.2f}, y={:.2f}, z={:.2f} {}'.format(scale[2], scale[1], scale[0], scaling['unit']))\n",
    "    #scale=(z_scale*eds_each_nth_slice, x_scale/math.cos(38), x_scale)\n",
    "    with napari.gui_qt():\n",
    "        viewer = napari.view_image(corrected_sem_images, name='SEM images', scale=scale)\n",
    "        for i, selected_element in enumerate(image_stacks):\n",
    "            print(i, selected_element)\n",
    "            new_layer = viewer.add_image(image_stacks[selected_element], name='EDS results for {}'.format(selected_element), scale=scale, colormap=colormaps[i], opacity=1, blending=\"additive\", rendering=\"iso\")\n",
    "        viewer.scale_bar.visible = True\n",
    "else:\n",
    "    print('no elements found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loading 672 images...\n",
      "\n",
      "trying to detect FEI scaling\n",
      "SEM image saved by an FEI / thermoScientific device - probaply created by FIB process\n",
      "Found existing translation csv, loading...\n",
      "Create 3D image stack with corrected image translation\n",
      "  - allocating 3D image space..\n",
      "  - translating and denoising images..\n",
      "saving images..\n",
      "saved \"F:/2020_11_19 C3S 28d+EDX/Images/SEM Image/aligned\\aligned_stack_(672).tif\"\n",
      "sucessfull\n",
      "672\n",
      "(19.2, 9.41609063976502, 8.993060000000002)\n"
     ]
    }
   ],
   "source": [
    "folder = sem_folder\n",
    "translation, error_list, filled_canvas, loaded_images, scaling = process_translation_of_folder(folder=folder, multicore=True, do_nlm=False, mask_size=0.99, eq_hist=True, crop_thresh=0 )\n",
    "print(len(loaded_images))\n",
    "\n",
    "im_cnt = len(loaded_images)\n",
    "z_scale=19.2\n",
    "scale=(z_scale, scaling['y'], scaling['x'])\n",
    "print(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "redo_translation = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found existing translation csv, loading...\n"
     ]
    }
   ],
   "source": [
    "translation_csv = folder + os.sep + 'translations_fixed_y.csv'\n",
    "fixed_translation = load_translation_csv( translation_csv, im_cnt )\n",
    "if (len(fixed_translation) != im_cnt-1 or redo_translation):\n",
    "    normed_scale = scale#(1, 1, 1)\n",
    "    with napari.gui_qt():\n",
    "        viewer = napari.view_image(filled_canvas, name='select y correction line', scale=normed_scale )\n",
    "\n",
    "    correction_dict = {}\n",
    "    for point in viewer.layers[1].data[0]:\n",
    "        correction_dict[math.floor(point[0])] = point[1]\n",
    "\n",
    "    y_correction_list = get_axis_correction_list( correction_dict, im_cnt )\n",
    "\n",
    "    for i, y in enumerate(y_correction_list):\n",
    "        #print(i, y, translation[i-1][1], translation[i-1][1] - y)\n",
    "        if i>0: translation[i-1][1] -= y\n",
    "    save_translation_csv( translation, translation_csv)\n",
    "else:\n",
    "    translation = fixed_translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found existing translation csv, loading...\n"
     ]
    }
   ],
   "source": [
    "translation_csv = folder + os.sep + 'translations_fixed_xy.csv'\n",
    "fixed_translation = load_translation_csv( translation_csv, im_cnt )\n",
    "if (len(fixed_translation) != im_cnt-1 or redo_translation):\n",
    "    normed_scale = scale#(1, 1, 1)\n",
    "    corrected_images = create_3D_stack(translation, loaded_images, False)\n",
    "    with napari.gui_qt():\n",
    "        viewer = napari.view_image(corrected_images, name='select x correction line', scale=normed_scale )\n",
    "        viewer.scale_bar.visible = True\n",
    "\n",
    "    correction_dict = {}\n",
    "    for point in viewer.layers[1].data[0]:\n",
    "        correction_dict[math.floor(point[0])] = point[0]\n",
    "\n",
    "    x_correction_list = get_axis_correction_list( correction_dict, z_slice_count )\n",
    "\n",
    "    for i, x in enumerate(x_correction_list):\n",
    "        # print(i, x, translation[i-1][2], translation[i-1][2] - x)\n",
    "        if i>0: translation[i-1][2] += x\n",
    "    save_translation_csv( translation, translation_csv)\n",
    "\n",
    "    \n",
    "else:\n",
    "    translation = fixed_translation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Create 3D image stack with corrected image translation\n  - allocating 3D image space..\n  - translating and denoising images..\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# preprocess the raw eds images - denoising, contrast enhancing and segmentation\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(1,1))\n",
    "def preprocess_sem_image(img):\n",
    "    tmp = clahe.apply(cv2.medianBlur(img, 9))\n",
    "\n",
    "    return clahe.apply( tmp )\n",
    "    \n",
    "for i, img in enumerate(loaded_images):\n",
    "    loaded_images[i] = preprocess_sem_image(img)\n",
    "\n",
    "\n",
    "# final stack arrangement\n",
    "corrected_sem_images = create_3D_stack(translation, loaded_images, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(19.2, 9.41609063976502, 8.993060000000002)\n"
     ]
    }
   ],
   "source": [
    "with napari.gui_qt():\n",
    "    viewer = napari.view_image(corrected_sem_images, name='Set ROI rectangle', scale=scale)\n",
    "    viewer.scale_bar.visible = True\n"
   ]
  },
  {
   "source": [
    "shapes_found = False\n",
    "a_list = []            \n",
    "b_list = []            \n",
    "for layer in viewer.layers:\n",
    "    if layer.name == \"Shapes\":\n",
    "        if len(viewer.layers[1].data[0]) == 4:\n",
    "            shapes_found = True\n",
    "            for point in viewer.layers[1].data[0]:\n",
    "                a = round(point[1])\n",
    "                b = round(point[2])\n",
    "                if not a in a_list: a_list.append(a)\n",
    "                if not b in b_list: b_list.append(b)\n",
    "        else:\n",
    "            print('found less or more points than expected ({})'.format(len(viewer.layers[1].data[0])))\n",
    "if not shapes_found:\n",
    "    print('no shape found')\n",
    "\n",
    "a_list.sort()\n",
    "b_list.sort()\n",
    "\n",
    "with napari.gui_qt():\n",
    "    viewer = napari.view_image(corrected_sem_images[ :, a_list[0]:a_list[1], b_list[0]:b_list[1] ], name='high resolution stack', scale=scale)\n",
    "    viewer.scale_bar.visible = True"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 32,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[   0.          562.07324152  415.44189122]\n [   0.         1926.40321703  415.44189122]\n [   0.         1926.40321703 1729.1177064 ]\n [   0.          562.07324152 1729.1177064 ]]\n[562, 1926] [415, 1729]\n(672, 2314, 2118)\n(672, 1364, 1314)\n"
     ]
    }
   ]
  },
  {
   "source": [
    "refFilename = \"SEM Image - SliceImage - 001.tif\"\n",
    "print(\"Reading reference image : \", refFilename)\n",
    "im_a = cv2.imread(refFilename, cv2.IMREAD_GRAYSCALE)\n",
    "print(im_a.shape)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Read image to be aligned\n",
    "imFilename = \"SEM Image - SliceImage - 003.tif\"\n",
    "print(\"Reading image to align : \", imFilename);  \n",
    "im_b = cv2.imread(imFilename, cv2.IMREAD_GRAYSCALE)\n",
    "print(im_b.shape)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#im_a_denoised = im_a#denoiseNLMCV2( im_a )\n",
    "#im_b_denoised = im_b#denoiseNLMCV2( im_b )\n",
    "gauss_kernel = (3, 3)\n",
    "im_a_denoised = cv2.GaussianBlur(im_a, gauss_kernel, cv2.BORDER_DEFAULT)\n",
    "im_b_denoised = cv2.GaussianBlur(im_b, gauss_kernel, cv2.BORDER_DEFAULT)\n",
    "\n",
    "mask = get_centered_mask(im_a, mask_size = 0.75)\n",
    "masked_im_a = cv2.bitwise_and(im_a_denoised, im_a_denoised, mask = mask)\n",
    "masked_im_b = cv2.bitwise_and(im_b_denoised, im_b_denoised, mask = mask)\n",
    "\n",
    "\n",
    "#fig=plt.figure(figsize=(col*5, row*5))\n",
    "#plt.imshow(im_b, cmap='gray')"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "col = 2\n",
    "row = 3\n",
    "fig=plt.figure(figsize=(col*5, row*5))\n",
    "plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, \n",
    "            hspace = 0, wspace = 0)\n",
    "            \n",
    "plt.margins(0,0)\n",
    "plt.axis('off')\n",
    "fig.add_subplot(row, col, 1)\n",
    "plt.axis('off')\n",
    "plt.imshow(im_a, cmap='gray')\n",
    "fig.add_subplot(row, col, 2)\n",
    "plt.axis('off')\n",
    "plt.imshow(im_b, cmap='gray')\n",
    "fig.add_subplot(row, col, 3)\n",
    "plt.axis('off')\n",
    "plt.imshow(im_a_denoised, cmap='gray')\n",
    "fig.add_subplot(row, col, 4)\n",
    "plt.axis('off')\n",
    "plt.imshow(im_b_denoised, cmap='gray')\n",
    "fig.add_subplot(row, col, 5)\n",
    "plt.axis('off')\n",
    "plt.imshow(masked_im_a, cmap='gray')\n",
    "fig.add_subplot(row, col, 6)\n",
    "plt.axis('off')\n",
    "plt.imshow(masked_im_b, cmap='gray')"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Registered image will be resotred in imReg. \n",
    "# The estimated homography will be stored in h. \n",
    "print(im_b_denoised.shape)\n",
    "imReg, h = alignImages(im_b_denoised, im_a_denoised, mask=mask)\n",
    "print(imReg.shape)\n"
   ],
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   }
  },
  {
   "source": [
    "fig=plt.figure(figsize=(10, 10))\n",
    "plt.imshow(imReg, cmap='gray')"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\n",
    "t_x = h[0,2]\n",
    "t_y = h[1,2]\n",
    "# only extract x and y movement\n",
    "# https://stackoverflow.com/questions/25658443/calculating-scale-rotation-and-translation-from-homography-matrix\n",
    "h_new=np.array([[1,0,t_x],[0,1,t_y],[0,0,1]])\n",
    "print(math.ceil(t_x),math.ceil(t_y))\n",
    "# Use homography\n",
    "height, width = im_b_denoised.shape\n",
    "im1Reg = cv2.warpPerspective(im_b_denoised, h_new, (math.ceil(width+t_x), math.ceil(height+t_y)))\n",
    "print(im1Reg.shape)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "fig=plt.figure(figsize=(10, 10))\n",
    "plt.imshow(im1Reg, cmap='gray')"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "immatches = cv2.imread('matches.tif', cv2.IMREAD_COLOR)\n",
    "fig=plt.figure(figsize=(10 , 5))\n",
    "plt.imshow(immatches)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Write aligned image to disk. \n",
    "outFilename = \"aligned.tif\"\n",
    "print(\"Saving aligned image : \", outFilename); \n",
    "cv2.imwrite(outFilename, imReg)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd01baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253",
   "display_name": "Python 3.8.5 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}